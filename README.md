# AI Friend - AI Chat Companion

A fine-tuned conversational AI model based on Google's Gemma 3 270M, designed for emotional support and companionship.

## ğŸš€ Features

- **Fine-tuned Model**: Custom-trained Gemma 3 270M for conversational AI
- **Emotional Support**: Designed to provide empathetic and supportive responses
- **Interactive Chat Interface**: Web-based chat application with Gradio
- **Efficient Training**: Uses LoRA (Low-Rank Adaptation) for parameter-efficient fine-tuning

## ğŸ“ Project Structure

```
gemma3-27m-test/
â”œâ”€â”€ chat_interface.py          # Gradio chat application
â”œâ”€â”€ api_server.py             # FastAPI backend server
â”œâ”€â”€ web_server.py             # Web server for frontend
â”œâ”€â”€ start_app.py              # Startup script for both servers
â”œâ”€â”€ train_model.py            # Model training script
â”œâ”€â”€ test_model.py             # Model testing script
â”œâ”€â”€ training_data/            # Training datasets
â”‚   â”œâ”€â”€ raw_data.json         # Original training data
â”‚   â”œâ”€â”€ train.json            # Processed training data
â”‚   â”œâ”€â”€ test.json             # Test dataset
â”‚   â””â”€â”€ expanded_train.json   # Enhanced training dataset
â”œâ”€â”€ trained_model/            # Final trained model
â”œâ”€â”€ model_checkpoints/        # Training checkpoints
â”œâ”€â”€ old_model/               # Previous model version
â”œâ”€â”€ old_checkpoints/         # Previous checkpoints
â”œâ”€â”€ static/                  # Frontend static files
â”‚   â””â”€â”€ index.html          # Main HTML interface
â”œâ”€â”€ gemma-env/               # Python virtual environment
â””â”€â”€ requirements_mac.txt     # Dependencies
```

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd gemma3-27m-test
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv gemma-env
   source gemma-env/bin/activate  # On macOS/Linux
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements_mac.txt
   ```

## ğŸ¯ Usage

### Training the Model

```bash
python train_model.py
```

This will:
- Load the Gemma 3 270M base model
- Fine-tune it on the conversational dataset
- Save the trained model to `./trained_model/`

### Testing the Model

```bash
python test_model.py
```

This will test the model with various conversational prompts to verify its performance.

### Running the Chat Interface

#### Option 1: Gradio Interface (Simple)
```bash
python chat_interface.py
```

#### Option 2: Professional Web Interface (Recommended)
```bash
# Start both API and web servers
python start_app.py

# Or start them separately:
python api_server.py    # API server on port 8001
python web_server.py    # Web server on port 3000
```

Then open your browser and go to: `http://localhost:3000`

**Features:**
- ğŸ’¬ Professional chat interface with voice capabilities
- ğŸ¤ Voice recognition and text-to-speech
- ğŸ’• Beautiful animations and floating hearts
- ğŸ“± Fully responsive design
- ğŸ”„ Real-time conversation with context
- ğŸ¨ Modern gradient animations
- ğŸ“± Fully responsive design for all devices
- ğŸ”„ Real-time conversation with last Q&A context
- ğŸ¯ Efficient message handling and professional animations
- ğŸ¨ Beautiful gradient animations and modern UI

## ğŸ”§ Model Details

- **Base Model**: Google Gemma 3 270M (Instruction-tuned)
- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)
- **Training Data**: 59 conversational examples
- **Training Epochs**: 5
- **Learning Rate**: 5e-4

## ğŸ“Š Training Parameters

- **LoRA Rank**: 16
- **LoRA Alpha**: 32
- **Target Modules**: q_proj, v_proj, k_proj, o_proj, gate_proj, up_proj, down_proj
- **Batch Size**: 2
- **Gradient Accumulation**: 4 steps

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project uses the Gemma 3 model which is subject to Google's responsible AI license.

## âš ï¸ Disclaimer

This is a research project for educational purposes. The model is designed for conversational AI and emotional support, but should not replace professional mental health services.
